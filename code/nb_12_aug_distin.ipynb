{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673f354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# generators\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# custom\n",
    "from datasets import IMB_DATASETS, load_data, prepare_data\n",
    "from attacks import smote_detection_attack, calculate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642ab9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1d64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4663cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GEN_FITS = 25\n",
    "\n",
    "# number of nearest neighbors used in SMOTE\n",
    "K = 5\n",
    "SAMPLING_STRATEGY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ad4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CUSTOM_KWARGS = {\n",
    "    \"solar_flare_m0\": {\"nbs_multiplte\": 5},  # there are duplicates\n",
    "    \"abalone\": {\"nbs_multiplte\": 10},\n",
    "    \"abalone_19\": {\"nbs_multiplte\": 3},\n",
    "    # \"diabetes\": {\"use_hull\": False, \"nbs_multiplte\": 5}, # there is categorical data\n",
    "    # \"phoneme\": {\"use_hull\": False, \"nbs_multiplte\": 10}, # there are duplicates\n",
    "}\n",
    "\n",
    "# ecoli (nbs_multiplte=2) -- 35/35\n",
    "# yeast_me2 (nbs_multiplte=2)  -- 51/51\n",
    "# solar_flare_m0 (nbs_multiplte=5) -- 58/58 (there are duplicates)\n",
    "# abalone (nbs_multiplte=10) -- 391/391\n",
    "# car_eval_34 (nbs_multiplte=2) -- 134/134\n",
    "# car_eval_4 (nbs_multiplte=2) -- 65/65\n",
    "# mammography (nbs_multiplte=2) -- 254/254 (there are duplicates)\n",
    "# abalone_19 (nbs_multiplte=2) -- 32/32\n",
    "\n",
    "# diabetes (nbs_multiplte=5) -- 268/268 (if we remove the hull; there's categorical data)\n",
    "# phoneme (nbs_multiplte=10) -- 1560/1560 (if we remove the hull; there are duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d92d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04b189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoli: f1 -- 1.0000 +- 0.0000\n",
      "yeast_me2: f1 -- 1.0000 +- 0.0000\n",
      "solar_flare_m0: f1 -- 1.0000 +- 0.0000\n",
      "abalone: f1 -- 0.9993 +- 0.0024\n",
      "car_eval_34: f1 -- 1.0000 +- 0.0000\n",
      "car_eval_4: f1 -- 1.0000 +- 0.0000\n",
      "mammography: f1 -- 0.9976 +- 0.0030\n",
      "abalone_19: f1 -- 0.9954 +- 0.0224\n",
      "          dataset         precision            recall                f1\n",
      "0           ecoli  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "1       yeast_me2  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "2  solar_flare_m0  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "3         abalone  0.9988 +- 0.0042  0.9998 +- 0.0007  0.9993 +- 0.0024\n",
      "4     car_eval_34  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "5      car_eval_4  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "6     mammography  0.9952 +- 0.0059  1.0000 +- 0.0000  0.9976 +- 0.0030\n",
      "7      abalone_19  0.9926 +- 0.0361  0.9988 +- 0.0061  0.9954 +- 0.0224\n"
     ]
    }
   ],
   "source": [
    "columns = [\"dataset\", \"precision\", \"recall\", \"f1\"]\n",
    "scores_df = pd.DataFrame(columns=columns, dtype=str)\n",
    "\n",
    "\n",
    "for data_name in IMB_DATASETS:\n",
    "    X, y = load_data(data_name)\n",
    "    X, y = prepare_data(X, y)\n",
    "\n",
    "    precs, recs, f1s = [], [], []\n",
    "    for i in range(N_GEN_FITS):\n",
    "        generator = SMOTE(k_neighbors=K, sampling_strategy=SAMPLING_STRATEGY)\n",
    "        X_augmented, y_augmented = generator.fit_resample(X, y)\n",
    "\n",
    "        r = (y_augmented == 1).sum() / (y == 1).sum()\n",
    "        \n",
    "        detected_real_minority = smote_detection_attack(X_augmented, y_augmented, k=K, r=r, **DATASET_CUSTOM_KWARGS.get(data_name, {}))\n",
    "        precision, recall, f1 = calculate_scores(X, y, detected_real_minority)\n",
    "        precs.append(precision)\n",
    "        recs.append(recall)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    data_socres = [f\"{data_name}\",\n",
    "                   f\"{np.array(precs).mean():.4f} +- {np.array(precs).std():.4f}\",\n",
    "                   f\"{np.array(recs).mean():.4f} +- {np.array(recs).std():.4f}\",\n",
    "                   f\"{np.array(f1s).mean():.4f} +- {np.array(f1s).std():.4f}\"\n",
    "                   ]\n",
    "    scores_df = pd.concat([scores_df, pd.DataFrame([data_socres], columns=columns)], ignore_index=True)\n",
    "    print(f\"{data_name}: f1 -- {np.array(f1s).mean():.4f} +- {np.array(f1s).std():.4f}\")\n",
    "\n",
    "print(scores_df)\n",
    "# scores_df.to_csv(\"results/augment/detect_smote.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d38c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
