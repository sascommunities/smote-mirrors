{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673f354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# generators\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# custom\n",
    "from datasets import IMB_DATASETS, load_data, prepare_data\n",
    "from attacks import smote_detection_attack, smote_reconstruction_attack, calculate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642ab9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf8cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0dffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1d64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4663cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GEN_FITS = 5\n",
    "\n",
    "# number of nearest neighbors used in SMOTE\n",
    "K = 2\n",
    "SAMPLING_STRATEGY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ad4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CUSTOM_KWARGS = {\n",
    "    \"ecoli\": {\"nbs_multiplte\": 3},\n",
    "    \"yeast_me2\": {\"nbs_multiplte\": 3},\n",
    "    \"solar_flare_m0\": {\"nbs_multiplte\": 5},  # there are duplicates\n",
    "    \"abalone\": {\"nbs_multiplte\": 25},\n",
    "    \"car_eval_34\": {\"nbs_multiplte\": 3},\n",
    "    \"car_eval_4\": {\"nbs_multiplte\": 3},\n",
    "    \"mammography\": {\"nbs_multiplte\": 5},\n",
    "    \"abalone_19\": {\"nbs_multiplte\": 3},\n",
    "    # \"diabetes\": {\"use_hull\": False, \"nbs_multiplte\": 5}, # there is categorical data\n",
    "    # \"phoneme\": {\"use_hull\": False, \"nbs_multiplte\": 10}, # there are duplicates\n",
    "}\n",
    "\n",
    "# ecoli (nbs_multiplte=2) -- 35/35\n",
    "# yeast_me2 (nbs_multiplte=2)  -- 51/51\n",
    "# solar_flare_m0 (nbs_multiplte=5) -- 58/58 (there are duplicates)\n",
    "# abalone (nbs_multiplte=10) -- 391/391\n",
    "# car_eval_34 (nbs_multiplte=2) -- 134/134\n",
    "# car_eval_4 (nbs_multiplte=2) -- 65/65\n",
    "# mammography (nbs_multiplte=2) -- 254/254 (there are duplicates)\n",
    "# abalone_19 (nbs_multiplte=2) -- 32/32\n",
    "\n",
    "# diabetes (nbs_multiplte=5) -- 268/268 (if we remove the hull; there's categorical data)\n",
    "# phoneme (nbs_multiplte=10) -- 1560/1560 (if we remove the hull; there are duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d92d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b04b189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoli: f1 -- 1.0000 +- 0.0000\n",
      "yeast_me2: f1 -- 1.0000 +- 0.0000\n",
      "solar_flare_m0: f1 -- 1.0000 +- 0.0000\n",
      "abalone: f1 -- 1.0000 +- 0.0000\n",
      "car_eval_34: f1 -- 1.0000 +- 0.0000\n",
      "car_eval_4: f1 -- 1.0000 +- 0.0000\n",
      "mammography: f1 -- 1.0000 +- 0.0000\n",
      "abalone_19: f1 -- 1.0000 +- 0.0000\n",
      "          dataset         precision            recall                f1\n",
      "0           ecoli  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "1       yeast_me2  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "2  solar_flare_m0  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "3         abalone  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "4     car_eval_34  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "5      car_eval_4  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "6     mammography  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n",
      "7      abalone_19  1.0000 +- 0.0000  1.0000 +- 0.0000  1.0000 +- 0.0000\n"
     ]
    }
   ],
   "source": [
    "columns = [\"dataset\", \"precision\", \"recall\", \"f1\"]\n",
    "scores_df = pd.DataFrame(columns=columns, dtype=str)\n",
    "\n",
    "\n",
    "for data_name in IMB_DATASETS:\n",
    "    X, y = load_data(data_name)\n",
    "    X, y = prepare_data(X, y)\n",
    "\n",
    "    precs, recs, f1s = [], [], []\n",
    "    for i in range(N_GEN_FITS):\n",
    "        generator = SMOTE(k_neighbors=K, sampling_strategy=SAMPLING_STRATEGY)\n",
    "        X_augmented, y_augmented = generator.fit_resample(X, y)\n",
    "\n",
    "        r = (y_augmented == 1).sum() / (y == 1).sum()\n",
    "        \n",
    "        detected_real_minority = smote_detection_attack(X_augmented, y_augmented, k=K, r=r, **DATASET_CUSTOM_KWARGS.get(data_name, {}))\n",
    "        precision, recall, f1 = calculate_scores(X, y, detected_real_minority)\n",
    "        precs.append(precision)\n",
    "        recs.append(recall)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    data_socres = [f\"{data_name}\",\n",
    "                   f\"{np.array(precs).mean():.4f} +- {np.array(precs).std():.4f}\",\n",
    "                   f\"{np.array(recs).mean():.4f} +- {np.array(recs).std():.4f}\",\n",
    "                   f\"{np.array(f1s).mean():.4f} +- {np.array(f1s).std():.4f}\"\n",
    "                   ]\n",
    "    scores_df = pd.concat([scores_df, pd.DataFrame([data_socres], columns=columns)], ignore_index=True)\n",
    "    print(f\"{data_name}: f1 -- {np.array(f1s).mean():.4f} +- {np.array(f1s).std():.4f}\")\n",
    "    # print(f\"{data_name}: precision -- {np.array(precs).mean():.4f} +- {np.array(precs).std():.4f}\")\n",
    "    # print(f\"{data_name}: recall -- {np.array(recs).mean():.4f} +- {np.array(recs).std():.4f}\")\n",
    "\n",
    "print(scores_df)\n",
    "# scores_df.to_csv(\"results/augment/detect_smote.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f8849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d38c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87b628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a94be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GEN_FITS = 5\n",
    "\n",
    "# number of nearest neighbors used in SMOTE\n",
    "K = 2\n",
    "SAMPLING_STRATEGY = 1\n",
    "\n",
    "inter_multiple=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752196ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e7329d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoli, s/n_1 7.60: f1 -- 0.6035 +- 0.0547\n",
      "yeast_me2, s/n_1 27.10: f1 -- 0.7343 +- 0.0161\n",
      "solar_flare_m0, s/n_1 18.43: f1 -- 0.5710 +- 0.0235\n",
      "abalone, s/n_1 8.68: f1 -- 0.5898 +- 0.0163\n",
      "car_eval_34, s/n_1 10.90: f1 -- 0.7569 +- 0.0112\n",
      "car_eval_4, s/n_1 24.58: f1 -- 0.7500 +- 0.0000\n",
      "mammography, s/n_1 41.01: f1 -- 0.7567 +- 0.0053\n",
      "abalone_19, s/n_1 128.53: f1 -- 0.6610 +- 0.0113\n",
      "          dataset imbalance         precision            recall  \\\n",
      "0           ecoli      7.60  1.0000 +- 0.0000  0.4343 +- 0.0554   \n",
      "1       yeast_me2     27.10  1.0000 +- 0.0000  0.5804 +- 0.0200   \n",
      "2  solar_flare_m0     18.43  1.0000 +- 0.0000  0.4000 +- 0.0229   \n",
      "3         abalone      8.68  1.0000 +- 0.0000  0.4184 +- 0.0164   \n",
      "4     car_eval_34     10.90  1.0000 +- 0.0000  0.6090 +- 0.0146   \n",
      "5      car_eval_4     24.58  1.0000 +- 0.0000  0.6000 +- 0.0000   \n",
      "6     mammography     41.01  1.0000 +- 0.0000  0.6087 +- 0.0069   \n",
      "7      abalone_19    128.53  1.0000 +- 0.0000  0.4938 +- 0.0125   \n",
      "\n",
      "                 f1  \n",
      "0  0.6035 +- 0.0547  \n",
      "1  0.7343 +- 0.0161  \n",
      "2  0.5710 +- 0.0235  \n",
      "3  0.5898 +- 0.0163  \n",
      "4  0.7569 +- 0.0112  \n",
      "5  0.7500 +- 0.0000  \n",
      "6  0.7567 +- 0.0053  \n",
      "7  0.6610 +- 0.0113  \n"
     ]
    }
   ],
   "source": [
    "columns = [\"dataset\", \"imbalance\", \"precision\", \"recall\", \"f1\"]\n",
    "scores_df = pd.DataFrame(columns=columns, dtype=str)\n",
    "\n",
    "for data_name in IMB_DATASETS:\n",
    "    X, y = load_data(data_name)\n",
    "    X, y = prepare_data(X, y)\n",
    "    \n",
    "    precs, recs, f1s = [], [], []\n",
    "    for i in range(N_GEN_FITS):\n",
    "        generator = SMOTE(k_neighbors=K, sampling_strategy=SAMPLING_STRATEGY)\n",
    "        X_augmented, y_augmented = generator.fit_resample(X, y)\n",
    "        \n",
    "        X_synthetic = X_augmented[len(y):]\n",
    "        y_synthetic = y_augmented[len(y):]\n",
    "        r = len(y_synthetic) / (y == 1).sum()\n",
    "\n",
    "        reconstructed_real_minority = smote_reconstruction_attack(X_synthetic, y_synthetic, k=K, r=r, inter_multiple=inter_multiple)\n",
    "        precision, recall, f1 = calculate_scores(X, y, reconstructed_real_minority, exact_match=False, line_eps=1e-12)\n",
    "        precs.append(precision)\n",
    "        recs.append(recall)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    data_socres = [f\"{data_name}\",\n",
    "                   f\"{r:.2f}\",\n",
    "                   f\"{np.array(precs).mean():.4f} +- {np.array(precs).std():.4f}\",\n",
    "                   f\"{np.array(recs).mean():.4f} +- {np.array(recs).std():.4f}\",\n",
    "                   f\"{np.array(f1s).mean():.4f} +- {np.array(f1s).std():.4f}\"\n",
    "                ]\n",
    "    scores_df = pd.concat([scores_df, pd.DataFrame([data_socres], columns=columns)], ignore_index=True)\n",
    "    print(f\"{data_name}, s/n_1 {r:.2f}: f1 -- {np.array(f1s).mean():.4f} +- {np.array(f1s).std():.4f}\")\n",
    "    # print(f\"{data_name}, s/n_1 {r:.2f}: precision -- {np.array(precs).mean():.4f} +- {np.array(precs).std():.4f}\")\n",
    "    # print(f\"{data_name}, s/n_1 {r:.2f}: recall -- {np.array(recs).mean():.4f} +- {np.array(recs).std():.4f}\")\n",
    "\n",
    "print(scores_df)\n",
    "# scores_df.to_csv(\"results/synth/recon_smote.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661dae12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3170cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp-smote",
   "language": "python",
   "name": "dp-smote"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
